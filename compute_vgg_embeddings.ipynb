{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPkDxwuRziPOEwPTxB3+Uu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabibo3/music-genre-classification/blob/main/compute_vgg_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7qVhELr20N2",
        "outputId": "e5150287-4ff8-4867-c61d-4e39c3484bf8"
      },
      "source": [
        "!pip install soundfile"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9_YYtEa27eX",
        "outputId": "4debfbc7-a8e7-418e-a622-a732e47c4b44"
      },
      "source": [
        "# Clone repo\r\n",
        "!rm -r music-genre-classification/\r\n",
        "!git clone https://github.com/fabibo3/music-genre-classification.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'music-genre-classification/': No such file or directory\n",
            "Cloning into 'music-genre-classification'...\n",
            "remote: Enumerating objects: 289, done.\u001b[K\n",
            "remote: Counting objects: 100% (289/289), done.\u001b[K\n",
            "remote: Compressing objects: 100% (188/188), done.\u001b[K\n",
            "remote: Total 289 (delta 168), reused 187 (delta 90), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (289/289), 87.92 KiB | 343.00 KiB/s, done.\n",
            "Resolving deltas: 100% (168/168), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o_D2Gg82-Vh",
        "outputId": "22e40fe8-f31e-4a15-aa53-32d741757fbc"
      },
      "source": [
        "# Mount google drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_0BjQd325Q5"
      },
      "source": [
        "import librosa, librosa.display\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import soundfile as sf\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "import librosa\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "from tqdm import tqdm\r\n",
        "from audioread.exceptions import NoBackendError\r\n",
        "\r\n",
        "# Load the model.\r\n",
        "vggmodel = hub.load('https://tfhub.dev/google/vggish/1')\r\n",
        "\r\n",
        "def embedding_from_fn(fn):\r\n",
        "  x, sr = librosa.load(fn) #,sr=None\r\n",
        "  x_16k = librosa.resample(x,sr,16000) #resample to 16KHz\r\n",
        "  embedding = np.array(vggmodel(x_16k)) \r\n",
        "  return embedding\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dt1wfhk6SPJ",
        "outputId": "b108564e-cfc8-4c98-8f81-0bf4ea62cbbc"
      },
      "source": [
        "# Train data\r\n",
        "\r\n",
        "dataset = []\r\n",
        "valid_ids = []\r\n",
        "not_valid = []\r\n",
        "\r\n",
        "file_dir = \"/content/drive/MyDrive/data/train/Train/\"\r\n",
        "files = os.listdir(file_dir)\r\n",
        "files = sorted(files)\r\n",
        "for fn in tqdm(files):\r\n",
        "    fn_full = os.path.join(file_dir, fn)\r\n",
        "    try:\r\n",
        "      emb = embedding_from_fn(fn_full)\r\n",
        "      dataset.append(emb[0:295]) # limit if required\r\n",
        "      #print('taille embed : ', emb.shape)\r\n",
        "      valid_ids.append(int(fn.split(\".\")[0]))\r\n",
        "    except NoBackendError:\r\n",
        "      not_valid.append(fn)\r\n",
        "\r\n",
        "print(\"Files not valid:\", not_valid)\r\n",
        "\r\n",
        "# Pickle\r\n",
        "valid_ids = np.asarray(valid_ids)\r\n",
        "dataset = np.asarray(dataset)\r\n",
        "id_file_name = \"/content/drive/MyDrive/data/train/preprocessed/vgg_train_ids_new.pickle\"\r\n",
        "data_file_name = \"/content/drive/MyDrive/data/train/preprocessed/vgg_train_new.pickle\"\r\n",
        "pickle.dump(valid_ids, open(id_file_name, \"wb\"))\r\n",
        "pickle.dump(dataset, open(data_file_name, \"wb\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 12/4000 [00:46<4:40:57,  4.23s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t9OIUot76Ov"
      },
      "source": [
        "# Check\r\n",
        "ids = pickle.load(open(id_file_name, \"rb\"))\r\n",
        "print(ids.shape)\r\n",
        "print(ids[0])\r\n",
        "\r\n",
        "data = pickle.load(open(data_file_name, \"rb\"))\r\n",
        "print(data.shape)\r\n",
        "print(data[0])\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VSvELH49mJ9"
      },
      "source": [
        "#Test data\r\n",
        "\r\n",
        "dataset = []\r\n",
        "valid_ids = []\r\n",
        "not_valid = []\r\n",
        "\r\n",
        "file_dir = \"/content/drive/MyDrive/data/test/Test/\"\r\n",
        "files = os.listdir(file_dir)\r\n",
        "files = sorted(files)\r\n",
        "for fn in tqdm(files[:5]):\r\n",
        "    fn_full = os.path.join(file_dir, fn)\r\n",
        "    try:\r\n",
        "      emb = embedding_from_fn(fn_full)\r\n",
        "      dataset.append(emb[0:295]) # limit if required\r\n",
        "      #print('taille embed : ', emb.shape)\r\n",
        "      valid_ids.append(int(fn.split(\".\")[0]))\r\n",
        "    except NoBackendError:\r\n",
        "      not_valid.append(fn)\r\n",
        "\r\n",
        "print(\"Files not valid:\", not_valid)\r\n",
        "\r\n",
        "# Pickle\r\n",
        "valid_ids = np.asarray(valid_ids)\r\n",
        "dataset = np.asarray(dataset)\r\n",
        "id_file_name = \"/content/drive/MyDrive/data/test/preprocessed/vgg_test_ids_new.pickle\"\r\n",
        "data_file_name = \"/content/drive/MyDrive/data/test/preprocessed/vgg_test_new.pickle\"\r\n",
        "pickle.dump(valid_ids, open(id_file_name, \"wb\"))\r\n",
        "pickle.dump(dataset, open(data_file_name, \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmIgZi-X91Vk"
      },
      "source": [
        "# Check\r\n",
        "ids = pickle.load(open(id_file_name, \"rb\"))\r\n",
        "print(ids.shape)\r\n",
        "print(ids[0])\r\n",
        "\r\n",
        "data = pickle.load(open(data_file_name, \"rb\"))\r\n",
        "print(data.shape)\r\n",
        "print(data[0])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}